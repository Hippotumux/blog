---
title: 從0開始的機器學習_1
# icon: material-symbols:add-notes-outline
order: 1
date: 2023-08-02
category:
  - ML

tag:
  - note
  - theorem

---


目前在學機器學習，所以做筆記紀錄一下，說一下，吳恩達老師的會是比較理論的形式，那之後我也會寫一篇以代碼為路線的筆記，不過從實戰或理論下手其實看個人，學完會再寫一篇來講述我對於這兩個的結論以及心得。

影片參考[吴恩达机器学习系列课程](https://www.bilibili.com/video/BV164411b7dx/?p=2&spm_id_from=pageDriver&vd_source=1163f03eb192d949135cb83df54fce2c)
課程講義[github](https://github.com/TheisTrue/MLofAndrew-Ng)


本篇主要是想要跟大家介紹一下什麼是機器學習，沒有什麼數學的部分 (不過說認真的，之後需要點數學基礎)

<!-- more -->

## 什麼是機器學習 

### 定義

- Arthur Samuel(1959): Field of study that gives computers the ability to learn without being explicitly programmed.
- Tom Mitchell(1998): Acomputer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E 

前者比較不正式，是比較舊的定義。後者是T.M提出的新定義
他說，計算機程序從經驗E中學習，解決某任務T，進行某一性能度量P，透過P測定在T上的表驗因經驗E而提高。 看起來超級繞口令的!

舉個跳棋遊戲例子，經驗E就是程序和自己下幾萬次跳棋，任務T就是玩跳棋，P就是與新對手玩跳棋時贏的機率。

### 練習題

根據Tom Mitchell的定義，你將那些不要的郵件標記為垃圾郵件，所以讓你的郵件程序學會了如何更好的過濾垃圾郵件，那這個例子中的E T P各是什麼。

- E:觀察使用者將不要的郵件標記為垃圾郵件
- T:郵件分類
- P:正確歸類郵件機率


### Machine Learning algorithms


機器學習主要分成下列四種

- Supervised learning (監督式學習)
- Unsupervised learning (非監督式學習)
- Reinforcement Learning (強化學習)
- recommender systems (推薦系統)
- 其他


## 監督式學習


在了解監督式學習前，先來看幾個例子

### 例子_房價預測

![](https://i.imgur.com/Xdt7Yod.png)

一個數據集，縱軸是不同房子價格，橫軸是不同房屋的平方英尺數，假設你的朋友有一棟750平方英尺的房子，他想要知道賣掉房子能賺多少錢。那麼學習算法可以幫你什麼呢?

學習算法會根據數據劃一條線(粉紅色)，或者說用一條直線擬和數據，對應750上去，差不多就是15萬美金。但是這可能不是你唯一的學習算法，也可能是用二次函數(藍色)來擬和數據會更好，看上去會接近20萬美金。

我們給了一個有正確答案的數據集，即該房子的賣價(紅色叉叉)，算法目的是給出更多的正確答案，更專業的術語，會稱為回歸問題(想要預測連續數值的輸出)

### 例子_線乳癌預測

![](https://i.imgur.com/BNdKOMS.png)

想透過醫療紀錄，設法預測線乳癌是惡性還是良性的，假設某人發現了一個線乳癌瘤，即乳房上的腫塊，惡性就是有害且危險的(Tumer)，在醫療紀錄中，橫軸是腫瘤的尺寸，縱軸代表是(1)或否(0)，也就是是否式惡性腫瘤。

數據為下(紅色代表惡性，藍色是良性)
![](https://i.imgur.com/mmlJ9Na.png)

假設你有個朋友的腫瘤大小在粉紅色箭頭的位置，我們想要判斷該腫瘤是良性還是惡性的機率，用專業的術語來說，這是一個分類問題(0 or 1)。

在分類問題中，有另一種方式來繪製這些數據，我們直接對應下去
![](https://i.imgur.com/fh3Elf0.png)

### 例子_線乳癌預測2


假設我們知道乳癌的大小，還知道病人的年紀
![](https://i.imgur.com/Tu2Jjh1.png)

然後你有一個朋友在粉紅色的位置，所以在我們給定的數據上，學習算法能做的就是在數據上劃出一條線，來分開良性跟惡性腫瘤。
![](https://i.imgur.com/pnm5oyJ.png)

所以你的學習算法得出的結論會是良性的可能性比惡性的還要大，在這個例子中，我們有兩個特徵，分別式年紀跟腫瘤大小，在其他機器學習算法中，往往我們會有更多的特徵，例如增加腫瘤的厚度，腫瘤細胞大小的均勻性...

那假設我們想要處理無窮多個特徵來預測，要怎麼處理呢？ 如何在電腦中儲存無窮多數量的事物？

在Support Vector Machine(向量機算法)中，有個數學方法，允許電腦處理無窮多的特徵。

### 結論

我們在上面討論了監督學習，想法是對於數據中的每個樣本，想要預測得出"正確答案"，像是房價或是腫瘤惡性還是良性。 討論了回歸問題，回歸指的是我們的目標是預測一個連續值輸出，也討論了分類問題，預測離散值的輸出。

總結：監督學習分成兩大類(分類問題(classification problem)、回歸問題(regression problem))
- 回歸問題：基於已有或未來的值，預測連續值
- 分類問題：將問題分類(例如01分類)，預測答案

### 練習題

問題1：假設你有幾千件相同的物品要賣，你想預測在接下來三個月內，能賣出多少件？
問題2：你有很多的用戶，你想要寫個軟件，來檢查每個客戶的帳戶，判斷這個帳戶是否會被入侵或破壞？

問題1,2應歸為分類問題還是回歸問題？

- 第一個問題：要預測三個月內能賣多少件，肯定要分析之前賣的結果然後對應接下來三個月，所以要預測連續值輸出-> 回歸問題
- 第二個問題：判斷帳戶是否會被入侵還是破壞 -> 分類問題


## 非監督式學習

在上面的監督學習中，每個樣本都被清楚的告知了，正確答案是"什麼"

![](https://i.imgur.com/Qnm0AqN.png)

但在非監督學習中，所用的數據和之前的不同，看上去會向下面這樣，並沒有標籤。

![](https://i.imgur.com/bFdJtdo.png)

我們不知道可以拿來做什麼，也不知道每個數據點究竟是什麼，指得到了一個數據集。

在非監督學習可能會判斷數據集包含兩個不同的族，這稱為clustering algorithm(聚類算法)

### 例子_Google新聞

[連結](https://news.google.com/)
google 新聞每天做的事情為在網路上收集幾萬幾十萬新聞，然後將他們組合成一個個的新聞專題。
![](https://i.imgur.com/wAi1d8t.png)

很多篇跟該事件有關的新聞會被顯示在一起。

### 例子_基因組合學


思想：給定一組不同的個體，對於每個個體，檢測他們是否擁有某個特定的基因，也就是檢測特定基因的表達程度。

![](https://i.imgur.com/l232r0T.jpg)

這些顏色展示了不同的個體擁有特定基因的程度，然後能做的就是進行聚類算法，把不同的個體，歸入不同的類別，或歸為不同類別的人。

我們沒有提前告知這個算法那些是第一類人，第二類人等等，相反的我們只是告訴算法，這裡有一堆數據，我不知道這些數據是什麼，能找出這些數據的結構嗎？並且我們沒有給數據集的"正確答案"給算法，那這就是監督算法。

### 例子_雞尾酒算法

想像一下，有一個宴會人數眾多，大家都在說話，所以會有很多聲音混雜再一起，很難聽清楚前面的人所說的話，假設宴會上只有兩個人，兩個人面對面，前面擺著兩個麥克風，各自離其中一個人比較近，所以收音的話，第一個人在一號麥克風會比較響，反之。

![](https://i.imgur.com/QYJ4rNo.png)

但兩個麥克風都會錄到兩個說話者重疊的聲音，雞尾酒算法會分離兩個被疊加再一起的聲音。(很像去人聲，去背景音的感覺)

但這個看起來很麻煩很複雜，但實際上只需要一行。

![](https://i.imgur.com/rkzkp4W.png)
？？？？？？？？ (好扯)

當然研究員想了非常久才得出的結論。

###練習題(多選) 

![](https://i.imgur.com/m3czPDQ.png)

- A (監督學習)
- B (非監督學習)
- C (非監督學習)
- D (監督學習)

答案為BC


## 後記

大家是不是更清楚機器學習到底在做什麼了，下一篇筆記會講梯度學習法以及正規方程，不會到很困難~
